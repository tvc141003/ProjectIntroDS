{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"padding: 20px; color: cyan; margin: 0; font-size: 30px; font-family: Arial; text-align: left; border-radius: 5px; background-color: #000000; border: 2px solid blue;\"><b>Preprocessing</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\" font-family: Arial; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #008B8B; padding: 15px; border-top: 2px solid blue; border-bottom: 2px solid blue;\n",
    "\"><b>Import</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_module import make_dataset\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\" font-family: Arial; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #008B8B; padding: 15px; border-top: 2px solid blue; border-bottom: 2px solid blue;\n",
    "\"><b>Exploring</b> data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "Read raw data </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_path = '../train.csv'\n",
    "raw_test_path = '../test.csv'\n",
    "\n",
    "raw_train_df = pd.read_csv(raw_train_path)\n",
    "raw_test_df = pd.read_csv(raw_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "How many rows and how many columns does the raw data have? </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = raw_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "print(f\"Current shape: {shape}\")\n",
    "\n",
    "if shape[0] > 1000:\n",
    "    print(f\"Your data good!.\")\n",
    "else:\n",
    "    print(f\"Your raw data absolutely small. Please choose larger year interval.!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "What does each line mean? Does it matter if the lines have different meanings? </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Text)\n",
    "<span style=\"font-size:14px; font-family:Verdana; color: #ffffff;\"> \n",
    "TODO: Your observation\n",
    "</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "Does the raw data have duplicate rows?  </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = raw_train_df.index\n",
    "detectDupSeries = index.duplicated(keep='first')\n",
    "num_duplicated_rows = detectDupSeries.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_duplicated_rows == 0:\n",
    "    print(f\"Your raw data have no duplicated line.!\")\n",
    "else:\n",
    "    if num_duplicated_rows > 1:\n",
    "        ext = \"lines\"\n",
    "    else:\n",
    "        ext = \"line\"\n",
    "    print(f\"Your raw data have {num_duplicated_rows} duplicated \" + ext + \". Please de-deduplicate your raw data.!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-deduplicate your raw data\n",
    "if num_duplicated_rows > 0:\n",
    "    raw_train_df = raw_train_df.drop_duplicates(keep='first')\n",
    "    print('Shape after de-deduplicate: ', raw_train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "What data type does each column currently have? Are there any columns whose data types are not suitable for further processing?  </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = raw_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Text)\n",
    "<span style=\"font-size:14px; font-family:Verdana; color: #ffffff;\"> \n",
    "TODO: Your observation\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "For each column with numeric data type, how are the values distributed? </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_info_train_df = raw_train_df.select_dtypes(exclude=['object', 'bool'])\n",
    "\n",
    "def missing_ratio(s):\n",
    "    return (s.isna().mean() * 100).round(1)\n",
    "\n",
    "def median(df):\n",
    "    return (df.quantile(0.5)).round(1)\n",
    "\n",
    "def lower_quartile(df):\n",
    "    return (df.quantile(0.25)).round(1)\n",
    "\n",
    "def upper_quartile(df):\n",
    "    return (df.quantile(0.75)).round(1)\n",
    "\n",
    "num_col_info_train_df = num_col_info_train_df.agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_info_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Optional)\n",
    "# You can use Matplotlib to visualize this table for more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(num_col_info_train_df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "For each column with a non-numeric data type, how are the values distributed? </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[//]: <> (Text)\n",
    "<span style=\"font-size:14px; font-family:Arial; color: #ffffff;\"> \n",
    "\n",
    "For non-numeric columns in a Pandas DataFrame, calculate the following:\n",
    "\n",
    "- Percentage of missing values: This is the percentage of values in the column that are missing, from 0 to 100.\n",
    "- Number of unique values: This is the number of different values in the column, excluding missing values. For categorical columns, this is the same as the number of categories.\n",
    "- Percentage of each value: This is the percentage of each unique value in the column, sorted by decreasing percentage. Missing values are excluded from this calculation.\n",
    "\n",
    "To calculate the percentage of each value, you can use a dictionary to store the results, where the key is the value and the value is the percentage. For categorical columns, the method is the same.\n",
    "\n",
    "Save the results to a Pandas DataFrame called cat_col_info_df, with the following columns:\n",
    "\n",
    "- Column name: The name of the non-numeric column in the original DataFrame (raw_df)\n",
    "- missing_ratio: The percentage of missing values in the column\n",
    "- num_values: The number of unique values in the column, excluding missing values\n",
    "- value_ratios: A dictionary of the percentage of each unique value in the column, sorted by decreasing percentage\n",
    "\n",
    "To improve readability, round all values to one decimal place using the .round(1) method.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) # For clearly\n",
    "pd.set_option('display.max_columns', None) # For clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_info_df = raw_train_df.select_dtypes(include='object')\n",
    "\n",
    "def missing_ratio(s):\n",
    "    return (s.isna().mean() * 100).round(1)\n",
    "\n",
    "def num_values(s):\n",
    "    s = s.astype(str).str.split(';')\n",
    "    s = s.explode()\n",
    "    return len(s.value_counts())\n",
    "\n",
    "def value_ratios(s):\n",
    "    s = s.astype(str).str.split(';')\n",
    "    s = s.explode()\n",
    "    totalCount = (~s.isna()).sum()\n",
    "    return ((s.value_counts()/totalCount*100).round(1)).to_dict()\n",
    "\n",
    "cat_col_info_df = cat_col_info_df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Optional)\n",
    "# You can use Matplotlib to visualize this table for more intuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\" font-family: Arial; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #008B8B; padding: 15px; border-top: 2px solid blue; border-bottom: 2px solid blue;\n",
    "\"><b>Cleaning </b> data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Text)\n",
    "<span style=\"font-size:14px; font-family:Arial; color: #ffffff;\"> \n",
    "\n",
    "After identifying the basic statistical numbers that describe your data, we further need to determine the features that have a large number of missing values. Such features are not useful for the analysis stage and must be removed from the dataset.\n",
    "\n",
    "Depending on your goals, the threshold for \"large\" can be defined. Usually, if the percentage of missing values is greater than 75%, the column is dropped from the dataframe and an updated dataframe is returned.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_features(df: pd.DataFrame, missing_lst: dict = dict(num_col_info_train_df.iloc[0]), threshold: float = 75.0) -> pd.DataFrame:\n",
    "    \"\"\"Drop missing features from Pandas dataframe base on given threshold.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe for processing.\n",
    "        missing_lst (dict, optional): Dict missing value rate which calculated from previous stage. Defaults to dict(num_col_info_df.iloc[0]).\n",
    "        threshold (float, optional): User threshold for dropping. Defaults to 75.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataframe\n",
    "    \"\"\"\n",
    "    if (df is None) or (missing_lst is None) or (threshold is None):\n",
    "        print(f\"[LOG] Invalid.\")\n",
    "        raise ValueError\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid changing the original\n",
    "    df_cp = df.copy()\n",
    "    \n",
    "    # List to maintain the columns to drop\n",
    "    cols_to_trim = []\n",
    "    \n",
    "    for key, value in missing_lst.items():\n",
    "        if float(value) > threshold:\n",
    "            cols_to_trim.append(key)\n",
    "            \n",
    "    if len(cols_to_trim) > 0:\n",
    "        # drop the columns identified using the dataframe drop() method\n",
    "        df_cp = df_cp.drop(columns=cols_to_trim)\n",
    "        print(\"[LOG] Dropped column(s): \" + \" \".join(cols_to_trim))\n",
    "    else:\n",
    "        print(\"[LOG] Have no column(s) to trim.\")\n",
    "        \n",
    "    return df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = drop_missing_features(raw_train_df, dict(num_col_info_train_df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[//]: <> (Text)\n",
    "<span style=\"font-size:14px; font-family:Arial; color: #ffffff;\"> \n",
    "\n",
    "After remove features which have large missing values, our dataframe still have missing values. So that, we need to fill these missing values so that they can be used in analysis.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_missing_value(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Filling missing features from Pandas dataframe\n",
    "    \n",
    "    The first, you need to replace all None values with NaN, fillna only works on nans.\n",
    "    \n",
    "    After that, you replace all NaN values with the mean of the column values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe for processing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataframe\n",
    "    \"\"\"\n",
    "    if (df is None):\n",
    "        print(f\"[LOG] Invalid.\")\n",
    "        raise ValueError\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid changing the original\n",
    "    df_cp = df.copy()\n",
    "    \n",
    "    # Get the list of columns in the dataframe\n",
    "    cols_list = list(df_cp.columns)\n",
    "    \n",
    "    # Replace all None values with NaN, fillna only works on nans\n",
    "    df_cp.fillna(value=np.nan, inplace=True)\n",
    "    \n",
    "    # Replace all NaN values with the mean of the column values\n",
    "    for col in cols_list:\n",
    "        if df_cp[col].dtype in ['object', 'bool']:\n",
    "            df_cp[col].fillna((df_cp[col].mode()[0]), inplace=True)\n",
    "        elif df_cp[col].dtype in ['int64', 'float64']:\n",
    "            df_cp[col].fillna((df_cp[col].mean()), inplace=True)\n",
    "        \n",
    "    return df_cp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = filling_missing_value(df=raw_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_train_df.select_dtypes(exclude=['object', 'bool']).agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df.select_dtypes(include=['object', 'bool']).agg([missing_ratio, num_values, value_ratios])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\" font-family: Arial; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #008B8B; padding: 15px; border-top: 2px solid blue; border-bottom: 2px solid blue;\n",
    "\"><b>Transformating </b> data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style='font-size:15px; font-family:Arial; color: #87CEFA;'><b>\n",
    "Is the collected data reasonable? </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\" font-family: Arial; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #008B8B; padding: 15px; border-top: 2px solid blue; border-bottom: 2px solid blue;\n",
    "\"><b>Saving </b> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of features: {raw_train_df.shape[1]}\")\n",
    "raw_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "save_name_lst = ['train', 'test']\n",
    "for name in save_name_lst:\n",
    "    print(f\"Save {name} to ../data/processed/{name}_processed.csv\")\n",
    "    raw_train_df.to_csv(\"../data/processed/\" + name + \"_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
